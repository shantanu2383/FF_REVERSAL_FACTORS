# -*- coding: utf-8 -*-
"""FF Momentum.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9J4cY2R0qOfXujW6GNR6d-j14476nQv
"""

import pandas as pd
import statsmodels.formula.api as smf
import numpy as np
import matplotlib.pyplot as plt

!pip install pandasql
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima_model import ARIMA
from sklearn.metrics import mean_squared_error, mean_absolute_error

import math
import matplotlib.pyplot as plt
from datetime import datetime
import seaborn as sns
import pandasql as ps
from sqlite3 import connect
from google.colab import drive
drive.mount("/content/gdrive", force_remount=True)

conn=connect(':memory:')

#SET PATHS
main="/content/gdrive/MyDrive/FIMA SUMMER 2023/RISK MANAGEMENT/FAMA FRENCH FACTORS/_main/"
raw= main + '_raw/'
aux= raw + 'Cake Shop Realtime Fundamentals as of June 23, 2023/'
clean= main + '_clean/'

"""# 01. Import Cleaned Returns With Daily Size Portfolios"""

file='daily_returns_daily_size_sorts.csv'
daily_returns=pd.read_csv(clean + 'daily_returns_daily_size_sorts.csv')
daily_returns.columns

daily_returns=daily_returns[['date', 'ticker', 'daily_return', 'exchange', 'adj_close', 'mkt_cap_2', 'size_portfolio']].drop_duplicates()

"""# 02. Calculate Momentum Returns

**Prior Ret is from -250 to -21**
"""

# Ensure the DataFrame is sorted by ticker and date
daily_returns = daily_returns.sort_values(by=["ticker", "date"])

# Shift 'adj_close' back by 21 and 251 days
daily_returns['adj_close_shifted_21'] = daily_returns.groupby('ticker')['adj_close'].shift(21)
daily_returns['adj_close_shifted_251'] = daily_returns.groupby('ticker')['adj_close'].shift(251)

# Calculate the cumulative return
daily_returns['prior_month_ret'] = (daily_returns['adj_close_shifted_21'] / daily_returns['adj_close_shifted_251']) - 1

# Drop the temporary shifted columns and rows with missing 'prior_month_ret'
daily_returns = daily_returns.drop(columns=['adj_close_shifted_21', 'adj_close_shifted_251'])
daily_returns.dropna(subset=['prior_month_ret'], inplace=True)

"""# 03. Daily Return Sort"""

#filter for relevant exchanges
daily_returns=daily_returns[(daily_returns['exchange']=="NYSE") | (daily_returns['exchange']=="AMEX") | (daily_returns['exchange']=="NASDAQ")]
daily_returns['date']=pd.to_datetime(daily_returns['date'])

daily_returns_sorts= daily_returns.dropna(subset=['prior_month_ret', 'mkt_cap_2'])

#filter for NYSE stocks only
return_breakpoints=daily_returns_sorts[daily_returns['exchange']=="NYSE"]


q30_ret=return_breakpoints.groupby('date').apply(lambda x: np.quantile(x.prior_month_ret, 0.3))
q70_ret=return_breakpoints.groupby('date').apply(lambda x: np.quantile(x.prior_month_ret, 0.7))


#format these values as dataframes to match together

q30_ret=pd.DataFrame(q30_ret)
q30_ret=q30_ret.rename(columns={0: 'q30'})

q70_ret=pd.DataFrame(q70_ret)
q70_ret=q70_ret.rename(columns={0: 'q70'})

return_quantiles=pd.merge(q30_ret, q70_ret, on='date')


# Merge return_quantiles data into daily_returns based on date
return_quantiles.reset_index(inplace=True)
return_quantiles['date']=pd.to_datetime(return_quantiles['date'])
daily_returns = daily_returns_sorts.merge(return_quantiles[['date', 'q30', 'q70']], on='date', how='left')

#assign to relevant portfolios
daily_returns['return_portfolio']=np.where(daily_returns['prior_month_ret'] > daily_returns['q70'], 'H', np.where(daily_returns['q30']> daily_returns['prior_month_ret'], 'L', 'M'))

daily_returns.columns

"""# 04. Portfolio Construction"""

daily_returns=daily_returns[['ticker', 'date', 'adj_close', 'daily_return', 'prior_month_ret', 'mkt_cap_2', 'return_portfolio', 'size_portfolio']]
daily_returns.rename(columns={'prior_month_ret': 'prior_daily_ret', 'mkt_cap_2':'mkt_val'}, inplace=True)
main=daily_returns



valueWeightRet=main.groupby(['date', 'size_portfolio', 'return_portfolio']).apply(lambda x: np.average(pd.to_numeric(x['daily_return']), weights=pd.to_numeric(x['mkt_val'])))


valueWeightRet_df=pd.DataFrame(valueWeightRet)
valueWeightRet_df=valueWeightRet_df.reset_index(level=['size_portfolio', 'return_portfolio'])
portfolios=valueWeightRet_df

print(portfolios)

portfolios[0]=portfolios[0]-1
portfolios[0]*=100


x=['size_portfolio', 'return_portfolio']

for x in x:
  portfolios[x]=portfolios[x].apply(str)

portfolios['size_return_portfolio']=portfolios['size_portfolio'] + "/" + portfolios['return_portfolio']

portfolios=portfolios.drop(['size_portfolio', 'return_portfolio'], axis=1)
portfolios=pd.pivot(portfolios, columns='size_return_portfolio', values=0)
print(portfolios)
portfolios
x=['B/H', 'B/L', 'B/M', 'S/H', 'S/L', 'S/M']
for x in x:
  portfolios[x]=pd.to_numeric(portfolios[x], errors='coerce')

portfolios['mom']=0.5 * (portfolios['S/H'] + portfolios['B/H']) - 0.5 * (portfolios['S/L']+portfolios['B/L'])

"""# Import Fama French Data For Comparison"""

import pandas_datareader.data as web
from pandas_datareader.famafrench import get_available_datasets
datasets = get_available_datasets()
datasets

FF_MOM=[dataset for dataset in datasets if 'F-F_Momentum_Factor_daily' in dataset ]

FF_MOM=web.DataReader(FF_MOM[0],'famafrench',start='2017-11-01',end='2023-01-01')[0]

FF_MOM.reset_index(inplace=True)
FF_MOM['Date']=pd.to_datetime(FF_MOM['Date'])
FF_MOM

portfolios.reset_index(inplace=True)
portfolios['date']=pd.to_datetime(portfolios['date'])
mom=portfolios[['date', 'mom']]
checker = mom.merge(FF_MOM, left_on='date', right_on='Date', how='left')

checker.corr()

checker.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])

checker.columns

import matplotlib.pyplot as plt

# Assuming checker is a pandas DataFrame containing your time series data
# And 'date' is a column in checker containing the dates of each data point

plt.figure(figsize=(14, 7))
plt.plot(checker['date'], checker['mom'], label='Reconstruction of Momentum factor')
plt.plot(checker['date'], checker['Mom   '], label='Fama French Momentum Factor')
plt.title('Reconstruction of Momentum Factor vs Original FF Momentum Factor')
plt.xlabel('Date')
plt.ylabel('Factor Value')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Create scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(checker['mom'], checker['Mom   '], alpha=0.5)

# Add line of perfect correlation
limits = [np.min([plt.xlim(), plt.ylim()]), np.max([plt.xlim(), plt.ylim()])]  # get the current limits
plt.plot(limits, limits, color='red')  # plot a line from the lower left to the upper right

# Set the limits again
plt.xlim(limits)
plt.ylim(limits)

# Adding labels
plt.xlabel('Reconstruction of Momentum factor')
plt.ylabel('Fama French Momentum')
plt.title('Scatter plot with Line of Perfect Correlation')

plt.show()